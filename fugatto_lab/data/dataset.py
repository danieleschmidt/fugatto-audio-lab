"""Dataset and preprocessing utilities for audio data."""

import logging
import json
import numpy as np
from typing import Dict, Any, Optional, List, Union, Tuple
from pathlib import Path
import time
from dataclasses import dataclass

from ..core import AudioProcessor


logger = logging.getLogger(__name__)


@dataclass
class AudioSample:
    """Represents a single audio sample with metadata."""
    audio_path: str
    caption: str
    duration_seconds: float
    sample_rate: int
    tags: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None


class AudioDataset:
    """Dataset class for audio data with captions and metadata."""
    
    def __init__(self, samples: List[AudioSample], processor: Optional[AudioProcessor] = None):
        """Initialize audio dataset.
        
        Args:
            samples: List of audio samples
            processor: Audio processor for loading/preprocessing
        """
        self.samples = samples
        self.processor = processor or AudioProcessor()
        self._audio_cache = {}
        self.cache_enabled = True
        
        logger.info(f"AudioDataset initialized with {len(samples)} samples")
    
    def __len__(self) -> int:
        """Get dataset size."""
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """Get a single sample by index.
        
        Args:
            idx: Sample index
            
        Returns:
            Dictionary containing audio data and metadata
        """
        if idx >= len(self.samples):
            raise IndexError(f"Index {idx} out of range for dataset of size {len(self.samples)}")
        
        sample = self.samples[idx]
        
        # Check cache first
        if self.cache_enabled and idx in self._audio_cache:
            audio_data = self._audio_cache[idx]
        else:
            # Load audio
            try:
                audio_data = self.processor.load_audio(sample.audio_path)
                if self.cache_enabled:
                    self._audio_cache[idx] = audio_data
            except Exception as e:
                logger.error(f"Failed to load audio {sample.audio_path}: {e}")
                # Return silence as fallback
                audio_data = np.zeros(int(sample.duration_seconds * self.processor.sample_rate), dtype=np.float32)
        
        return {\n            'audio': audio_data,\n            'caption': sample.caption,\n            'audio_path': sample.audio_path,\n            'duration_seconds': sample.duration_seconds,\n            'sample_rate': sample.sample_rate,\n            'tags': sample.tags or [],\n            'metadata': sample.metadata or {},\n            'index': idx\n        }\n    \n    def get_batch(self, indices: List[int]) -> List[Dict[str, Any]]:\n        \"\"\"Get multiple samples by indices.\n        \n        Args:\n            indices: List of sample indices\n            \n        Returns:\n            List of sample dictionaries\n        \"\"\"\n        return [self[idx] for idx in indices]\n    \n    def filter_by_duration(self, min_duration: float = 0.0, max_duration: float = float('inf')) -> 'AudioDataset':\n        \"\"\"Filter dataset by audio duration.\n        \n        Args:\n            min_duration: Minimum duration in seconds\n            max_duration: Maximum duration in seconds\n            \n        Returns:\n            New filtered dataset\n        \"\"\"\n        filtered_samples = [\n            sample for sample in self.samples\n            if min_duration <= sample.duration_seconds <= max_duration\n        ]\n        \n        logger.info(f\"Filtered dataset: {len(self.samples)} -> {len(filtered_samples)} samples\")\n        return AudioDataset(filtered_samples, self.processor)\n    \n    def filter_by_tags(self, required_tags: List[str], any_tag: bool = False) -> 'AudioDataset':\n        \"\"\"Filter dataset by tags.\n        \n        Args:\n            required_tags: Tags that samples must have\n            any_tag: If True, sample needs any of the tags; if False, needs all tags\n            \n        Returns:\n            New filtered dataset\n        \"\"\"\n        def has_required_tags(sample_tags: Optional[List[str]]) -> bool:\n            if not sample_tags:\n                return False\n            \n            if any_tag:\n                return any(tag in sample_tags for tag in required_tags)\n            else:\n                return all(tag in sample_tags for tag in required_tags)\n        \n        filtered_samples = [\n            sample for sample in self.samples\n            if has_required_tags(sample.tags)\n        ]\n        \n        logger.info(f\"Tag filtered dataset: {len(self.samples)} -> {len(filtered_samples)} samples\")\n        return AudioDataset(filtered_samples, self.processor)\n    \n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get dataset statistics.\n        \n        Returns:\n            Dictionary with dataset statistics\n        \"\"\"\n        durations = [sample.duration_seconds for sample in self.samples]\n        sample_rates = [sample.sample_rate for sample in self.samples]\n        \n        # Collect all tags\n        all_tags = []\n        for sample in self.samples:\n            if sample.tags:\n                all_tags.extend(sample.tags)\n        \n        tag_counts = {}\n        for tag in all_tags:\n            tag_counts[tag] = tag_counts.get(tag, 0) + 1\n        \n        return {\n            'total_samples': len(self.samples),\n            'total_duration_hours': sum(durations) / 3600,\n            'avg_duration_seconds': np.mean(durations),\n            'min_duration_seconds': min(durations) if durations else 0,\n            'max_duration_seconds': max(durations) if durations else 0,\n            'sample_rates': list(set(sample_rates)),\n            'most_common_sample_rate': max(set(sample_rates), key=sample_rates.count) if sample_rates else None,\n            'unique_tags': len(tag_counts),\n            'most_common_tags': sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n        }\n    \n    def save_to_json(self, output_path: Union[str, Path]) -> None:\n        \"\"\"Save dataset metadata to JSON file.\n        \n        Args:\n            output_path: Path to save JSON file\n        \"\"\"\n        output_path = Path(output_path)\n        \n        dataset_data = {\n            'version': '1.0',\n            'created_at': time.time(),\n            'total_samples': len(self.samples),\n            'statistics': self.get_statistics(),\n            'samples': [\n                {\n                    'audio_path': sample.audio_path,\n                    'caption': sample.caption,\n                    'duration_seconds': sample.duration_seconds,\n                    'sample_rate': sample.sample_rate,\n                    'tags': sample.tags,\n                    'metadata': sample.metadata\n                }\n                for sample in self.samples\n            ]\n        }\n        \n        with open(output_path, 'w') as f:\n            json.dump(dataset_data, f, indent=2)\n        \n        logger.info(f\"Dataset saved to {output_path}\")\n    \n    @classmethod\n    def from_json(cls, json_path: Union[str, Path], \n                  processor: Optional[AudioProcessor] = None) -> 'AudioDataset':\n        \"\"\"Load dataset from JSON file.\n        \n        Args:\n            json_path: Path to JSON file\n            processor: Audio processor instance\n            \n        Returns:\n            AudioDataset instance\n        \"\"\"\n        with open(json_path, 'r') as f:\n            dataset_data = json.load(f)\n        \n        samples = [\n            AudioSample(\n                audio_path=sample_data['audio_path'],\n                caption=sample_data['caption'],\n                duration_seconds=sample_data['duration_seconds'],\n                sample_rate=sample_data['sample_rate'],\n                tags=sample_data.get('tags'),\n                metadata=sample_data.get('metadata')\n            )\n            for sample_data in dataset_data['samples']\n        ]\n        \n        logger.info(f\"Loaded dataset from {json_path}: {len(samples)} samples\")\n        return cls(samples, processor)\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear audio cache.\"\"\"\n        self._audio_cache.clear()\n        logger.info(\"Audio cache cleared\")\n\n\nclass DatasetPreprocessor:\n    \"\"\"Preprocessor for preparing audio datasets for training.\"\"\"\n    \n    def __init__(self, sample_rate: int = 48000, normalize_loudness: bool = True,\n                 target_lufs: float = -14.0, max_duration: float = 30.0):\n        \"\"\"Initialize dataset preprocessor.\n        \n        Args:\n            sample_rate: Target sample rate\n            normalize_loudness: Whether to normalize loudness\n            target_lufs: Target loudness in LUFS\n            max_duration: Maximum audio duration in seconds\n        \"\"\"\n        self.sample_rate = sample_rate\n        self.normalize_loudness = normalize_loudness\n        self.target_lufs = target_lufs\n        self.max_duration = max_duration\n        self.processor = AudioProcessor(sample_rate, target_lufs)\n        \n        logger.info(f\"DatasetPreprocessor initialized: {sample_rate}Hz, {target_lufs} LUFS\")\n    \n    def prepare_dataset(self, audio_dir: Union[str, Path], \n                       captions_file: Union[str, Path],\n                       output_dir: Optional[Union[str, Path]] = None,\n                       augment: bool = False) -> AudioDataset:\n        \"\"\"Prepare dataset from audio directory and captions file.\n        \n        Args:\n            audio_dir: Directory containing audio files\n            captions_file: JSON file with captions and metadata\n            output_dir: Optional directory to save processed audio\n            augment: Whether to apply data augmentation\n            \n        Returns:\n            Prepared AudioDataset\n        \"\"\"\n        audio_dir = Path(audio_dir)\n        captions_file = Path(captions_file)\n        \n        logger.info(f\"Preparing dataset from {audio_dir} with captions {captions_file}\")\n        \n        # Load captions\n        with open(captions_file, 'r') as f:\n            captions_data = json.load(f)\n        \n        samples = []\n        processed_count = 0\n        \n        for item in captions_data:\n            try:\n                audio_path = audio_dir / item['audio_file']\n                \n                if not audio_path.exists():\n                    logger.warning(f\"Audio file not found: {audio_path}\")\n                    continue\n                \n                # Load and preprocess audio\n                audio_data = self.processor.load_audio(audio_path)\n                \n                # Apply preprocessing\n                processed_audio = self._preprocess_audio(audio_data, augment)\n                \n                # Save processed audio if output directory specified\n                if output_dir:\n                    output_path = Path(output_dir) / f\"processed_{audio_path.name}\"\n                    output_path.parent.mkdir(parents=True, exist_ok=True)\n                    self.processor.save_audio(processed_audio, output_path)\n                    final_audio_path = str(output_path)\n                else:\n                    final_audio_path = str(audio_path)\n                \n                # Create sample\n                sample = AudioSample(\n                    audio_path=final_audio_path,\n                    caption=item['caption'],\n                    duration_seconds=len(processed_audio) / self.sample_rate,\n                    sample_rate=self.sample_rate,\n                    tags=item.get('tags'),\n                    metadata=item.get('metadata', {})\n                )\n                \n                samples.append(sample)\n                processed_count += 1\n                \n                if processed_count % 100 == 0:\n                    logger.info(f\"Processed {processed_count} audio files\")\n                    \n            except Exception as e:\n                logger.error(f\"Failed to process {item.get('audio_file', 'unknown')}: {e}\")\n                continue\n        \n        logger.info(f\"Dataset preparation completed: {len(samples)} samples\")\n        return AudioDataset(samples, self.processor)\n    \n    def _preprocess_audio(self, audio: np.ndarray, augment: bool = False) -> np.ndarray:\n        \"\"\"Preprocess single audio sample.\n        \n        Args:\n            audio: Input audio data\n            augment: Whether to apply augmentation\n            \n        Returns:\n            Preprocessed audio\n        \"\"\"\n        # Basic preprocessing\n        processed = self.processor.preprocess(\n            audio,\n            normalize=self.normalize_loudness,\n            trim_silence=True,\n            apply_filter=True\n        )\n        \n        # Trim to maximum duration\n        max_samples = int(self.max_duration * self.sample_rate)\n        if len(processed) > max_samples:\n            processed = processed[:max_samples]\n        \n        # Apply augmentation if requested\n        if augment:\n            processed = self._apply_augmentation(processed)\n        \n        return processed\n    \n    def _apply_augmentation(self, audio: np.ndarray) -> np.ndarray:\n        \"\"\"Apply data augmentation to audio.\n        \n        Args:\n            audio: Input audio\n            \n        Returns:\n            Augmented audio\n        \"\"\"\n        augmented = audio.copy()\n        \n        # Random volume scaling\n        if np.random.random() < 0.3:\n            volume_factor = np.random.uniform(0.7, 1.3)\n            augmented = augmented * volume_factor\n        \n        # Add slight noise\n        if np.random.random() < 0.2:\n            noise_level = 0.005 * np.random.random()\n            noise = np.random.normal(0, noise_level, len(augmented))\n            augmented = augmented + noise\n        \n        # Time shifting\n        if np.random.random() < 0.3:\n            shift_samples = int(np.random.uniform(-0.1, 0.1) * self.sample_rate)\n            if shift_samples > 0:\n                augmented = np.pad(augmented, (shift_samples, 0), mode='constant')[:-shift_samples]\n            elif shift_samples < 0:\n                augmented = np.pad(augmented, (0, -shift_samples), mode='constant')[-shift_samples:]\n        \n        # Ensure valid range\n        augmented = np.clip(augmented, -1.0, 1.0)\n        \n        return augmented\n    \n    def validate_dataset(self, dataset: AudioDataset) -> Dict[str, Any]:\n        \"\"\"Validate dataset for training readiness.\n        \n        Args:\n            dataset: Dataset to validate\n            \n        Returns:\n            Validation results\n        \"\"\"\n        issues = []\n        warnings = []\n        \n        # Check dataset size\n        if len(dataset) < 10:\n            issues.append(f\"Dataset too small: {len(dataset)} samples (minimum 10 recommended)\")\n        elif len(dataset) < 100:\n            warnings.append(f\"Small dataset: {len(dataset)} samples (100+ recommended)\")\n        \n        # Check audio files\n        missing_files = 0\n        duration_issues = 0\n        \n        for i in range(min(100, len(dataset))):  # Sample check\n            try:\n                sample = dataset[i]\n                audio_path = Path(sample['audio_path'])\n                \n                if not audio_path.exists():\n                    missing_files += 1\n                \n                if sample['duration_seconds'] > self.max_duration:\n                    duration_issues += 1\n                    \n            except Exception as e:\n                issues.append(f\"Error loading sample {i}: {e}\")\n        \n        if missing_files > 0:\n            issues.append(f\"{missing_files} audio files missing or inaccessible\")\n        \n        if duration_issues > 0:\n            warnings.append(f\"{duration_issues} samples exceed max duration {self.max_duration}s\")\n        \n        # Check captions\n        empty_captions = sum(1 for i in range(min(100, len(dataset))) if not dataset[i]['caption'].strip())\n        if empty_captions > 0:\n            warnings.append(f\"{empty_captions} samples have empty captions\")\n        \n        validation_result = {\n            'dataset_size': len(dataset),\n            'issues': issues,\n            'warnings': warnings,\n            'is_valid': len(issues) == 0,\n            'statistics': dataset.get_statistics()\n        }\n        \n        logger.info(f\"Dataset validation: {'PASS' if validation_result['is_valid'] else 'FAIL'}\")\n        return validation_result